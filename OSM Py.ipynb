{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap data wrangling with MongoDB\n",
    "\n",
    "###### by Alicia Dale; Project 3 of Udacity's Data Analyst Nanodegree Program\n",
    "\n",
    "\n",
    "What is OSM? Open Street Map is a type of software that is considered to be an example of volunteered geographical information. It currently has over 2 million registered users who contriubte to the Open Street Mapping foundation. With that many users the platform is prone to have many errors with the data that is being added to the software that so many people use. My task here is to take the data from a chosen area and clean it up! Make sure that words are not over abbreviated and that the data is clean and easy to read and utilize to be used in various applications such as FourSquare. Below is the step-by-step process for my data auditing and cleaning.\n",
    "How do I obtain the data necessary to audit? For this project I had to pick an area that I would like to do my data cleaning on. I chose Philadelphia since it's a place I had never been to and was hoping to learn a bit more about its location through this project. I had done that though this link https://www.openstreetmap.org/relation/188022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References used for the project: \n",
    "###### MongoDB docs: https://docs.mongodb.com/manual/\n",
    "###### GitHub project examples: https://github.com/dwmercier/Project-3-Data-Analyst-Nanodegree/blob/master/P3%20-%20Data%20Wrangling%20with%20MongoDB.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(SAMPLE_FILE, \\'wb\\') as output:\\n    output.write(\\'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n\\')\\n    output.write(\\'<osm>\\n  \\')\\n\\n    # Write every kth top level element\\n    for i, element in enumerate(get_element(OSM_FILE)):\\n        if i % k == 0:\\n            output.write(ET.tostring(element, encoding=\\'utf-8\\'))\\n\\n    output.write(\\'</osm>\\')\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.cElementTree as ET  \n",
    "''' Use cElementTree or lxml if too slow'''\n",
    "import pprint \n",
    "'''pretty printer- produces pleasing representations of your data structures'''\n",
    "from collections import defaultdict \n",
    "\n",
    "OSM_FILE = \"/Users/aliciadale/Desktop/philadelphia_pennsylvania.osm\"  # This line of code finds my OSM file for Philly\n",
    "SAMPLE_FILE = \"sample.osm\" # I am writing to to this file \n",
    "\n",
    "k = 10 \n",
    "''' Parameter: take every k-th top level element'''\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "'''\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ITERATIVE PARSING :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Since I have the data downloaded successfully I will now begin my auditing and cleaning of the data. I will start with iterative parsing which finds all the top level tags in the document such as, bounds and nodes then I will create a dictionary and add all the tag values to it and count how many of each tag is present in the datafile. Using a sample size file under 2GB of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Parse through the OSM file with ElementTree module to count the number of unique element types\"\"\"\n",
    "def count_tags(filename):\n",
    "        tags = {}\n",
    "        for event, elem in ET.iterparse(filename):\n",
    "            if elem.tag in tags: \n",
    "                tags[elem.tag] += 1\n",
    "                \"\"\"If element tag is an already found element then count it to the tag name, \n",
    "                    if not then create a new tag with the else statement\"\"\"\n",
    "            else:\n",
    "                tags[elem.tag] = 1\n",
    "        return tags    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': 1,\n",
       " 'member': 55682,\n",
       " 'nd': 3595591,\n",
       " 'node': 2959713,\n",
       " 'osm': 1,\n",
       " 'relation': 4601,\n",
       " 'tag': 1803393,\n",
       " 'way': 291519}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tags(OSM_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### The output illustrated above is a dictionary of all the different types of tags followed by their count or how often they appear in the philadephia_pennsylvania.osm file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAG TYPES :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### In further exploration of my OSM data file, I would like to check the \"k\" value for each tag element in the data, and find all potential problems. I created 3 expresions to check for certain paterns in the OSM file tags. I would like to change the original format of \n",
    "\"addr:street\"\n",
    "to \n",
    "{\"address\":{ \"street\" : \"some value\"}}\n",
    "\n",
    "(In order to change the format, I would like to see if we have any tags with problematic characters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 961953, 'lower_colon': 660978, 'other': 180457, 'problemchars': 5}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "\n",
    "        if lower.search(element.attrib['k']):\n",
    "            keys['lower'] = keys['lower'] + 1\n",
    "        \n",
    "\n",
    "        elif lower_colon.search(element.attrib['k']):\n",
    "            keys['lower_colon'] = keys['lower_colon'] + 1\n",
    "\n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys['problemchars'] = keys['problemchars'] + 1\n",
    "   \n",
    "        else:\n",
    "            keys['other'] = keys['other'] + 1 \n",
    "        pass\n",
    "        \n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "\n",
    "keys = process_map(OSM_FILE)\n",
    "pprint.pprint(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### The output presented above showcases all of the tags in my OSM file that fall into the 4 categories that I have created and gives me a count of problem characters in the file. That output is 5. So 5 tags have problematic characters that I will need to evaluate further in my analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORING USERS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### I want to find how many unique users have contriubted to OSM for the city of Philadelphia. I will need to write a function that returns a set of unique user ID's extracted from my OSM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1967"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"people invovlved in the map editing \"\"\"\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        for i in element:\n",
    "            if 'uid' in i.attrib:\n",
    "                users.add(i.attrib['uid'])\n",
    "    return users\n",
    "users = process_map(OSM_FILE)\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### The above output shows that 1967 users have contributed to Philadelphia's OSM data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auditing Street Names:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Here I would like to find all potential errors that I have found in the document that deal with expected common address errors. Such as the word \"road\" being abbreviated as rd as an example. After careful review of the document I found these problematic address errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': set(['Easton Rd #1',\n",
      "           'Route 1',\n",
      "           'S Newtown Street Rd #1',\n",
      "           'Walnut St #1']),\n",
      " '111': set(['South Clinton Avenue Ste. 111']),\n",
      " '168': set(['Marlton Pike East Ste. 168']),\n",
      " '19047': set(['200 Manor Ave. Langhorne, PA 19047',\n",
      "               '2245 E. Lincoln Hwy, Langhorne, PA 19047',\n",
      "               '2275 E Lincoln Hwy, Langhorne, PA 19047',\n",
      "               '2300  East Lincoln Highway, Pennsylvania 19047']),\n",
      " '19067': set(['East Trenton Avenue Morrisville, PA 19067']),\n",
      " '205': set(['Office Center Dr #205']),\n",
      " '206': set(['US 206', 'US 70 & US 206']),\n",
      " '315': set(['Heritage Center Dr #315']),\n",
      " '33': set(['33', 'Route 33']),\n",
      " '37th': set(['N 37th']),\n",
      " '38': set(['New Jersey 38', 'Route 38', 'State Route 38']),\n",
      " '39th': set(['N 39th']),\n",
      " '40': set(['1140 US Highway 40', 'Rt 40']),\n",
      " '4080': set(['4080']),\n",
      " '41st': set(['S. 41st']),\n",
      " '43rd': set(['N 43rd']),\n",
      " '446-1234': set(['1 Brookline BlvdHavertown, PA 19083(610) 446-1234']),\n",
      " '452': set(['Market Street; Pennsylvania Route 452',\n",
      "             'Pennel Road; Pennsylvania Route 452']),\n",
      " '5': set(['West Girard Avenue, 5']),\n",
      " '53rd': set(['N 53rd']),\n",
      " '611': set(['Easton Road Route 611']),\n",
      " '651': set(['W Ridge Pike #651']),\n",
      " '70': set(['State Route 70', 'US 70']),\n",
      " '73': set(['New Jersey 73', 'North Route 73', 'Route 73', 'State Route 73']),\n",
      " '80': set(['N Lewis RD Unit #80']),\n",
      " '902': set(['Chestnut Street #902']),\n",
      " 'A': set(['S Bethlehem Pike #A']),\n",
      " 'AVE': set(['EDGMONT AVE']),\n",
      " 'Alley': set(['Bradford Alley',\n",
      "               'Elfreths Alley',\n",
      "               'Horners Alley',\n",
      "               'Willings Alley']),\n",
      " 'Atreet': set(['Arch Atreet']),\n",
      " 'Ave': set(['517 W Girard Ave',\n",
      "             '72nd Ave and Orgontz Ave',\n",
      "             '8401 Frankford Ave',\n",
      "             'Alden Ave',\n",
      "             'Aramingo Ave',\n",
      "             'Bala Ave',\n",
      "             'Baltimore Ave',\n",
      "             'Bishop Ave, Clifton Ave',\n",
      "             'Bryn Mawr Ave',\n",
      "             'Chester Ave',\n",
      "             'Constitution Ave',\n",
      "             'Cottman Ave',\n",
      "             'Devon St & Mt. Pleasant Ave',\n",
      "             'E Butler Ave',\n",
      "             'E Lancaster Ave',\n",
      "             'E. Mt Airy Ave',\n",
      "             'East Lancaster Ave',\n",
      "             'East Wadsworth Ave',\n",
      "             'Essington Ave',\n",
      "             'Fairmount Ave',\n",
      "             'Fort Washington Ave',\n",
      "             'Frankford Ave',\n",
      "             'Germantown Ave',\n",
      "             'Grant Ave',\n",
      "             'Grays Ave',\n",
      "             'Hirst Ave',\n",
      "             'Lancaster Ave',\n",
      "             'Montgomery Ave',\n",
      "             'Mt.Ephraim Ave',\n",
      "             'N Olden Ave',\n",
      "             'Park Ave',\n",
      "             'Parkway Ave',\n",
      "             'Pennington Ave',\n",
      "             'Pennsylvania Ave',\n",
      "             'Penrose Ave',\n",
      "             'Philmont Ave',\n",
      "             'Rising Sun Ave',\n",
      "             'S Clinton Ave',\n",
      "             'S Washington Ave',\n",
      "             'S. Clinton Ave',\n",
      "             'Sharon Ave',\n",
      "             'Sloan Ave',\n",
      "             'Stenton Ave',\n",
      "             'Summit Ave',\n",
      "             'Towamencin Ave',\n",
      "             'W Chelten Ave',\n",
      "             'Washington Ave',\n",
      "             'West Butler Ave',\n",
      "             'West Girard Ave',\n",
      "             'West Glenside Ave',\n",
      "             'West Huntington Ave',\n",
      "             'West Mermaid Lane and Germantown Ave',\n",
      "             'West Montgomery Ave',\n",
      "             'West Trenton Ave']),\n",
      " 'Ave.': set(['Aramingo Ave.',\n",
      "              'Baltimore Ave.',\n",
      "              'Bonny Brook Ave.',\n",
      "              'East Butler Ave.',\n",
      "              'Germantown Ave.',\n",
      "              'Morton Ave.',\n",
      "              'Station Ave.',\n",
      "              'Taylor Ave.',\n",
      "              'West Butler Ave.']),\n",
      " 'B2': set(['Bristol Pike B2']),\n",
      " 'Bigler': set(['Bigler']),\n",
      " 'Blvd': set(['Brookline Blvd',\n",
      "              'Centennial Blvd',\n",
      "              'Floral Vale Blvd',\n",
      "              'Garden Gold Blvd',\n",
      "              'Garden Golf Blvd',\n",
      "              'Hearthstone Blvd',\n",
      "              'Nassau Park Blvd',\n",
      "              'Nassau Parl Blvd',\n",
      "              'S Christopher Columbus Blvd',\n",
      "              'Shannondell Blvd',\n",
      "              'W Cuthbert Blvd']),\n",
      " 'Blvd.': set(['Brookline Blvd.']),\n",
      " 'Broadway': set(['373 North Broadway', 'North Broadway', 'South Broadway']),\n",
      " 'Brown': set(['N 37th & Brown']),\n",
      " 'Bypass': set(['Pemberton Bypass']),\n",
      " 'C': set(['Aramingo Ave #C']),\n",
      " 'Center': set(['Town Center']),\n",
      " 'Chestnut': set(['Chestnut']),\n",
      " 'Chippendale': set(['Chippendale']),\n",
      " 'Cir': set(['Woodfield Cir']),\n",
      " 'Close': set(['Heaver Close']),\n",
      " 'Cricket': set(['Cricket']),\n",
      " 'Crossing': set(['Harpers Crossing', 'Painters Crossing']),\n",
      " 'Ct': set(['Portsmouth Ct']),\n",
      " 'D102': set(['Henry Ave #D102']),\n",
      " 'Dr': set(['2515 Metropolitan Dr',\n",
      "            'Deerpath Dr',\n",
      "            'Merrill Lynch Dr',\n",
      "            'Revere Dr',\n",
      "            \"Tommy's Meadow Dr\"]),\n",
      " 'E': set(['NJ-70 E']),\n",
      " 'East': set(['Cabot Boulevard East',\n",
      "              'Clementon Road East',\n",
      "              'High Street East',\n",
      "              'Kings Highway East',\n",
      "              'Lincoln Drive East',\n",
      "              'Marlton Pike East',\n",
      "              'North Independence Mall East',\n",
      "              'North Independence Ml East',\n",
      "              'Route 38 East',\n",
      "              'South Independence Mall East']),\n",
      " 'Extension': set(['Spruce Street Extension', 'Washington Street Extension']),\n",
      " 'Floor': set(['Race Street 2nd Floor']),\n",
      " 'Front': set(['S Front']),\n",
      " 'Garden': set(['Spring Garden']),\n",
      " 'Greene': set(['Greene']),\n",
      " 'Haverford': set(['Haverford']),\n",
      " 'Hutchinson': set(['North Hutchinson']),\n",
      " 'Hwy': set(['Harding Hwy', 'Lincoln Hwy']),\n",
      " 'Ln': set(['Patricia Ln', 'Simpkins Ln']),\n",
      " 'Mallon': set(['Mallon']),\n",
      " 'Manor': set(['Brynwood Manor']),\n",
      " 'Maple': set(['South Maple']),\n",
      " 'Market': set(['Market']),\n",
      " 'Master': set(['15th and Master']),\n",
      " 'Moore': set(['Cecil B. Moore']),\n",
      " 'NJ-73': set(['NJ-73']),\n",
      " 'Nixon': set(['Shawmont & Nixon']),\n",
      " 'North': set(['Delsea Drive North',\n",
      "               'Kings Highway North',\n",
      "               'Lakeview Drive North']),\n",
      " 'PA': set(['Baltimore Pike, Springfield, PA',\n",
      "            'E. Lincoln Highway Langhore, PA',\n",
      "            'Saxer Ave, Springfield, PA']),\n",
      " 'PA.': set(['Trenton Rd - Levittown, PA.']),\n",
      " 'PIke': set(['Princeton PIke']),\n",
      " 'Park': set(['Falsoa Park', 'Narbrook Park']),\n",
      " 'Plaza': set(['Dothan Plaza', 'Yorktown Plaza']),\n",
      " 'Preston': set(['N Preston']),\n",
      " 'ROAD': set(['DAVISVILLE ROAD', 'TERWOOD ROAD', 'TOWNSHIP LINE ROAD']),\n",
      " 'Rd': set(['22 Centerton Rd',\n",
      "            '24 Centerton Rd',\n",
      "            '40 Centerton Rd',\n",
      "            '50 Centerton Rd',\n",
      "            '52 Centerton Rd',\n",
      "            '58 Centerton Rd',\n",
      "            '62 Centerton Rd',\n",
      "            '66 Centerton Rd',\n",
      "            '70 Centerton Rd',\n",
      "            'Abrams Mill Rd',\n",
      "            'Almshouse Rd',\n",
      "            \"Arney's Mount Rd\",\n",
      "            'Barren Hill Rd',\n",
      "            'Briarwood Rd',\n",
      "            'Bristol Rd',\n",
      "            'Byberry Rd',\n",
      "            'Calcon Hook Rd',\n",
      "            'Church Rd',\n",
      "            'Clements Bridge Rd',\n",
      "            'Cross Keys Rd',\n",
      "            'Darby Rd',\n",
      "            'Deptford Center Rd',\n",
      "            'Durham Rd',\n",
      "            'E County Line Rd',\n",
      "            'Easton Rd',\n",
      "            'Edison Furlong Rd',\n",
      "            'Evesham Rd',\n",
      "            'Grove Rd',\n",
      "            'Haddonfield Rd',\n",
      "            'Hulmeville Rd',\n",
      "            'Hurffville  Rd',\n",
      "            'Hurffville Rd',\n",
      "            'Kimberton Rd',\n",
      "            'King Rd',\n",
      "            'Lincoln Mill Rd',\n",
      "            'Meetinghouse Rd',\n",
      "            'N Providence Rd',\n",
      "            'New Falls Rd',\n",
      "            'Old Cuthbert Rd',\n",
      "            'S Easton Rd',\n",
      "            'Schuylkill Rd',\n",
      "            'South Easton Rd',\n",
      "            'Stokes Rd',\n",
      "            'Valley Rd',\n",
      "            'Woodmount Rd',\n",
      "            'York Rd']),\n",
      " 'Rd.': set(['Clements Bridge Rd.',\n",
      "             'Kagey Rd.',\n",
      "             'N. Lewis Rd.',\n",
      "             'North Lewis Rd.',\n",
      "             'S. Chester Rd.',\n",
      "             'W. Street Rd.',\n",
      "             'Wistar Rd.',\n",
      "             'York Rd.']),\n",
      " 'Run': set(['Autumn River Run', 'Pheasant Run']),\n",
      " 'ST': set(['S 6TH ST']),\n",
      " 'Salina': set(['Salina']),\n",
      " 'Sheffield': set(['Sheffield']),\n",
      " 'Sloan': set(['Sloan']),\n",
      " 'South': set(['Lakeview Drive South', 'Route 130 South', 'Steel Road South']),\n",
      " 'Spruce': set(['Spruce']),\n",
      " 'Sreet': set(['Bridge Sreet']),\n",
      " 'Sstreet': set(['South 9th Sstreet']),\n",
      " 'St': set(['46th and Market St',\n",
      "            '507 E Tulpehocken St',\n",
      "            'Baring St',\n",
      "            'Bush St',\n",
      "            'Carson St',\n",
      "            'Center St',\n",
      "            'Chestnut St',\n",
      "            'Coates St',\n",
      "            'Cooper St',\n",
      "            'Dekalb St',\n",
      "            'Dickinson St',\n",
      "            'E Front St',\n",
      "            'E Hampton St',\n",
      "            'E Hector St',\n",
      "            'E Penn St',\n",
      "            'E State St',\n",
      "            'E Wingohocking St',\n",
      "            'E. Passyunk Ave and Kauffman St',\n",
      "            'Federal St',\n",
      "            'Front St & Tasker St',\n",
      "            'Green St',\n",
      "            'Johnston St',\n",
      "            'Market St',\n",
      "            'McKean St',\n",
      "            'N 3rd St',\n",
      "            'N 4th St',\n",
      "            'N 5th St',\n",
      "            'N 6th St',\n",
      "            'N Broad St',\n",
      "            'N Gratz St',\n",
      "            'N Main St',\n",
      "            'North Broad St',\n",
      "            'North Front St',\n",
      "            'Quarry St',\n",
      "            'Race St',\n",
      "            'Ranstead St',\n",
      "            'Rhawn St',\n",
      "            'S 19th St',\n",
      "            'S 20th St',\n",
      "            'S 22nd St',\n",
      "            'S 24th St',\n",
      "            'S 28th St',\n",
      "            'S 3rd St',\n",
      "            'S 41st St',\n",
      "            'S 47th St',\n",
      "            'S 4th St',\n",
      "            'S 50th St',\n",
      "            'S Broad St',\n",
      "            'S Main St',\n",
      "            'S Norwood St',\n",
      "            'S Warren St',\n",
      "            'South 40th St',\n",
      "            'South Bancroft St',\n",
      "            'South St',\n",
      "            'South St Bernard St',\n",
      "            'Spring Garden St',\n",
      "            'St John St',\n",
      "            'Starr St',\n",
      "            'W State St',\n",
      "            'Walnut St',\n",
      "            'Washington St',\n",
      "            'West Main St']),\n",
      " 'St.': set(['12th St.',\n",
      "             'Almond St.',\n",
      "             'Diamond St.',\n",
      "             'E. State St.',\n",
      "             'Mt. Pleasant Ave, Devon St, Sprague St.',\n",
      "             'N 24th St.',\n",
      "             'S. 15th St.',\n",
      "             'S. 40th St.',\n",
      "             'South Broad St.',\n",
      "             'W. State St.']),\n",
      " 'Steet': set(['South 18th Steet']),\n",
      " 'Stiles': set(['16th and Stiles']),\n",
      " 'StreetPhiladelphia': set(['117 South 18th StreetPhiladelphia']),\n",
      " 'Streets': set(['North 13th and Brown Streets']),\n",
      " 'Sts.': set(['1st and Seneca Sts.']),\n",
      " 'Sycamore': set(['North Sycamore']),\n",
      " 'Ter': set(['Greenview Ter']),\n",
      " 'Thompson': set(['Sletcher and Thompson']),\n",
      " 'US-130': set(['US-130']),\n",
      " 'Vine': set(['12th and Vine']),\n",
      " 'W': set(['NJ 70 W']),\n",
      " 'W5': set(['Presidential Blvd, Ste W5']),\n",
      " 'Walk': set(['Hamilton Walk',\n",
      "              'Liacouras Walk',\n",
      "              'Locust Walk',\n",
      "              'Polett Walk',\n",
      "              'Woodland Walk']),\n",
      " 'Warminster': set(['Warminster']),\n",
      " 'Warren': set(['Warren']),\n",
      " 'Way': set(['Applied Card Way',\n",
      "             'Arbor Way',\n",
      "             'Azalea Way',\n",
      "             'Bellows Way',\n",
      "             'Braxton Way',\n",
      "             'Eagle Way',\n",
      "             'Green Valley Way',\n",
      "             'Janton Way',\n",
      "             'Jennifer Way',\n",
      "             'Johnnys Way',\n",
      "             'Lafrance Way',\n",
      "             'Lantern Way',\n",
      "             'Lucretia Mott Way',\n",
      "             'Mather Way',\n",
      "             'Nina Way',\n",
      "             'Plaza Way',\n",
      "             'Rock Way',\n",
      "             'Scout Way',\n",
      "             'Technology Way',\n",
      "             'Triumphe Way',\n",
      "             \"Veteran's Way\",\n",
      "             'Westtown Way',\n",
      "             'Winston Way',\n",
      "             'Woodview Way']),\n",
      " 'West': set(['Cabot Boulevard West',\n",
      "              'North Independence Mall West',\n",
      "              'Old Marlton Pike West']),\n",
      " 'al': set(['pullen al']),\n",
      " 'ave': set(['Ridge ave',\n",
      "             'and 1891 brunswick ave',\n",
      "             'hillcrest ave',\n",
      "             'michigan ave']),\n",
      " 'avenue': set(['Ohio avenue']),\n",
      " 'drive': set(['Bucks Town drive']),\n",
      " 'ext': set(['brunswick ave ext']),\n",
      " 'king': set(['West king']),\n",
      " 'lane': set(['country club lane']),\n",
      " 'rd': set(['Cricket rd', 'Lawrenceville rd']),\n",
      " 'road': set(['Morehall road', 'Newtown-Langhorne road']),\n",
      " 'south': set(['Route 130 south']),\n",
      " 'st': set(['Main st',\n",
      "            'centre st',\n",
      "            'clay st',\n",
      "            'e front st',\n",
      "            'e state st',\n",
      "            'jackson st',\n",
      "            'livingston st',\n",
      "            'market st',\n",
      "            'mercer st',\n",
      "            'pear st',\n",
      "            's 3rd st',\n",
      "            's broad st',\n",
      "            's montgomery st',\n",
      "            's stockton st',\n",
      "            's warren st',\n",
      "            'w state st']),\n",
      " 'st.': set(['E. State st.']),\n",
      " 'street': set(['9th street',\n",
      "                'Broad street',\n",
      "                'East ontario street',\n",
      "                'Westmoreland street',\n",
      "                'chestnut street',\n",
      "                'tilton street']),\n",
      " 'susquahana': set(['thompson and susquahana']),\n",
      " 'way': set(['mortgage way'])}\n"
     ]
    }
   ],
   "source": [
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Avenue\", \"Boulevard\", \"Court\", \"Circle\", \"Drive\", \"Exit\", \"Highway\", \"Lane\",\n",
    "            \"Parkway\", \"Pike\", \"Place\", \"Road\", \"Square\", \"Suite\", \"Street\", \"Trail\", \"Terrace\"]\n",
    "\n",
    "\"\"\"the above \"expected\" variable contains all of the full words that can be contained in an address in my file\n",
    "the below \"mapping\" variable contains all of the mistake abbreviations that have been used in my OSM file and \n",
    "shows their proper format\"\"\"\n",
    "\n",
    "\n",
    "mapping = { \"Av\" : \"Avenue\",\n",
    "            \"avenue\" : \"Avenue\",\n",
    "            \"Ave\" : \"Avenue\",\n",
    "            \"Ave.\" : \"Avenue\",\n",
    "            \"ave\" : \"Avenue\",\n",
    "            \"Blvd\" : \"Boulevard\",\n",
    "            \"Crt\" : \"Court\",\n",
    "            \"Ct\" : \"Court\",\n",
    "            \"Cir\" : \"Circle\",\n",
    "            \"Dr\" : \"Drive\",\n",
    "            \"drive\" : \"Drive\",\n",
    "            \"Ext\" : \"Exit\",\n",
    "            \"ext\" : \"Exit\",\n",
    "            \"lane\" : \"Lane\",\n",
    "            \"Ln\" : \"Lane\",\n",
    "            \"PIke\" : \"Pike\",\n",
    "            \"Rd\" : \"Road\",\n",
    "            \"Rd.\" : \"Road\",\n",
    "            \"rd\" : \"Road\",\n",
    "            \"road\" : \"Road\",\n",
    "            \"Hwy\" : \"Highway\",\n",
    "            \"Sreet\" : \"Street\",\n",
    "            \"st\" : \"Street\", \n",
    "            \"ST\" : \"Street\",\n",
    "            \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Atreet\" : \"Street\",\n",
    "            \"Sstreet\" : \"Street\",\n",
    "            \"street\" : \"Street\",\n",
    "            \"Steet\" : \"Street\",\n",
    "            \"Sq\" : \"Square\",\n",
    "            \"Ste\" : \"Suite\",\n",
    "           \"Trl\" : \"Trail\",\n",
    "            \"Ter\" : \"Terrace\"}\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()  \n",
    "        \"\"\"groups street types together\"\"\"\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "            \"\"\"if street type is problematic add it to audit_street_type\"\"\"\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\") \n",
    "\"\"\"Searches K tags with the specific \"addr:street\" attribute\"\"\"\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "philly_street_types = audit(OSM_FILE)\n",
    "pprint.pprint(dict(philly_street_types)) #pprints dictionary created of all street types from OSM file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Now we will update the name of the streets. We will take the old name and update it to the new street name that is desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Brookline BlvdHavertown, PA 19083(610) 446-1234 => 1 Brookline BlvdHavertown, PA 19083(610) 446-1234\n",
      "Pennel Road; Pennsylvania Route 452 => Pennel Road; Pennsylvania Route 452\n",
      "Market Street; Pennsylvania Route 452 => Market Street; Pennsylvania Route 452\n",
      "52 Centerton Rd => 52 Centerton Road\n",
      "Clements Bridge Rd => Clements Bridge Road\n",
      "58 Centerton Rd => 58 Centerton Road\n",
      "E County Line Rd => E County Line Road\n",
      "Darby Rd => Darby Road\n",
      "Stokes Rd => Stokes Road\n",
      "Church Rd => Church Road\n",
      "York Rd => York Road\n",
      "Valley Rd => Valley Road\n",
      "62 Centerton Rd => 62 Centerton Road\n",
      "South Easton Rd => South Easton Road\n",
      "Durham Rd => Durham Road\n",
      "Lincoln Mill Rd => Lincoln Mill Road\n",
      "Evesham Rd => Evesham Road\n",
      "Barren Hill Rd => Barren Hill Road\n",
      "Bristol Rd => Bristol Road\n",
      "24 Centerton Rd => 24 Centerton Road\n",
      "Edison Furlong Rd => Edison Furlong Road\n",
      "Easton Rd => Easton Road\n",
      "Hulmeville Rd => Hulmeville Road\n",
      "70 Centerton Rd => 70 Centerton Road\n",
      "Grove Rd => Grove Road\n",
      "50 Centerton Rd => 50 Centerton Road\n",
      "22 Centerton Rd => 22 Centerton Road\n",
      "Hurffville Rd => Hurffville Road\n",
      "Arney's Mount Rd => Arney's Mount Road\n",
      "S Easton Rd => S Easton Road\n",
      "Kimberton Rd => Kimberton Road\n",
      "Almshouse Rd => Almshouse Road\n",
      "Woodmount Rd => Woodmount Road\n",
      "N Providence Rd => N Providence Road\n",
      "66 Centerton Rd => 66 Centerton Road\n",
      "New Falls Rd => New Falls Road\n",
      "Old Cuthbert Rd => Old Cuthbert Road\n",
      "Haddonfield Rd => Haddonfield Road\n",
      "Deptford Center Rd => Deptford Center Road\n",
      "Meetinghouse Rd => Meetinghouse Road\n",
      "Abrams Mill Rd => Abrams Mill Road\n",
      "Byberry Rd => Byberry Road\n",
      "Briarwood Rd => Briarwood Road\n",
      "Hurffville  Rd => Hurffville  Road\n",
      "Calcon Hook Rd => Calcon Hook Road\n",
      "40 Centerton Rd => 40 Centerton Road\n",
      "Schuylkill Rd => Schuylkill Road\n",
      "Cross Keys Rd => Cross Keys Road\n",
      "King Rd => King Road\n",
      "Ohio avenue => Ohio Avenue\n",
      "N 37th & Brown => N 37th & Brown\n",
      "Cricket => Cricket\n",
      "S Front => S Front\n",
      "Arch Atreet => Arch Street\n",
      "TERWOOD ROAD => TERWOOD ROAD\n",
      "TOWNSHIP LINE ROAD => TOWNSHIP LINE ROAD\n",
      "DAVISVILLE ROAD => DAVISVILLE ROAD\n",
      "South 9th Sstreet => South 9th Street\n",
      "N 53rd => N 53rd\n",
      "Woodfield Cir => Woodfield Circle\n",
      "N 37th => N 37th\n",
      "Princeton PIke => Princeton Pike\n",
      "Cecil B. Moore => Cecil B. Moore\n",
      "East Trenton Avenue Morrisville, PA 19067 => East Trenton Avenue Morrisville, PA 19067\n",
      "Chippendale => Chippendale\n",
      "Willings Alley => Willings Alley\n",
      "Horners Alley => Horners Alley\n",
      "Elfreths Alley => Elfreths Alley\n",
      "Bradford Alley => Bradford Alley\n",
      "Presidential Blvd, Ste W5 => Presidential Blvd, Ste W5\n",
      "Bristol Pike B2 => Bristol Pike B2\n",
      "373 North Broadway => 373 North Broadway\n",
      "North Broadway => North Broadway\n",
      "South Broadway => South Broadway\n",
      "Trenton Rd - Levittown, PA. => Trenton Rd - Levittown, PA.\n",
      "Warren => Warren\n",
      "Cabot Boulevard West => Cabot Boulevard West\n",
      "North Independence Mall West => North Independence Mall West\n",
      "Old Marlton Pike West => Old Marlton Pike West\n",
      "Heritage Center Dr #315 => Heritage Center Dr #315\n",
      "chestnut street => chestnut Street\n",
      "Broad street => Broad Street\n",
      "9th street => 9th Street\n",
      "tilton street => tilton Street\n",
      "Westmoreland street => Westmoreland Street\n",
      "East ontario street => East ontario Street\n",
      "South Clinton Avenue Ste. 111 => South Clinton Avenue Ste. 111\n",
      "Pemberton Bypass => Pemberton Bypass\n",
      "Sloan => Sloan\n",
      "NJ-70 E => NJ-70 E\n",
      "N Lewis RD Unit #80 => N Lewis RD Unit #80\n",
      "S 6TH ST => S 6TH Street\n",
      "Chestnut => Chestnut\n",
      "Pheasant Run => Pheasant Run\n",
      "Autumn River Run => Autumn River Run\n",
      "Sheffield => Sheffield\n",
      "Narbrook Park => Narbrook Park\n",
      "Falsoa Park => Falsoa Park\n",
      "Lawrenceville rd => Lawrenceville Road\n",
      "Cricket rd => Cricket Road\n",
      "Baltimore Pike, Springfield, PA => Baltimore Pike, Springfield, PA\n",
      "E. Lincoln Highway Langhore, PA => E. Lincoln Highway Langhore, PA\n",
      "Saxer Ave, Springfield, PA => Saxer Ave, Springfield, PA\n",
      "Aramingo Ave #C => Aramingo Ave #C\n",
      "North Sycamore => North Sycamore\n",
      "East Butler Ave. => East Butler Avenue\n",
      "Morton Ave. => Morton Avenue\n",
      "Germantown Ave. => Germantown Avenue\n",
      "Baltimore Ave. => Baltimore Avenue\n",
      "Station Ave. => Station Avenue\n",
      "West Butler Ave. => West Butler Avenue\n",
      "Taylor Ave. => Taylor Avenue\n",
      "Aramingo Ave. => Aramingo Avenue\n",
      "Bonny Brook Ave. => Bonny Brook Avenue\n",
      "Washington Street Extension => Washington Street Extension\n",
      "Spruce Street Extension => Spruce Street Extension\n",
      "Dothan Plaza => Dothan Plaza\n",
      "Yorktown Plaza => Yorktown Plaza\n",
      "Warminster => Warminster\n",
      "thompson and susquahana => thompson and susquahana\n",
      "16th and Stiles => 16th and Stiles\n",
      "15th and Master => 15th and Master\n",
      "1st and Seneca Sts. => 1st and Seneca Sts.\n",
      "E Lancaster Ave => E Lancaster Avenue\n",
      "Germantown Ave => Germantown Avenue\n",
      "Aramingo Ave => Aramingo Avenue\n",
      "517 W Girard Ave => 517 W Girard Avenue\n",
      "Rising Sun Ave => Rising Sun Avenue\n",
      "Pennington Ave => Pennington Avenue\n",
      "Bala Ave => Bala Avenue\n",
      "Frankford Ave => Frankford Avenue\n",
      "Fairmount Ave => Fairmount Avenue\n",
      "Alden Ave => Alden Avenue\n",
      "Lancaster Ave => Lancaster Avenue\n",
      "E Butler Ave => E Butler Avenue\n",
      "Baltimore Ave => Baltimore Avenue\n",
      "8401 Frankford Ave => 8401 Frankford Avenue\n",
      "Pennsylvania Ave => Pennsylvania Avenue\n",
      "West Montgomery Ave => West Montgomery Avenue\n",
      "Grant Ave => Grant Avenue\n",
      "Sloan Ave => Sloan Avenue\n",
      "Fort Washington Ave => Fort Washington Avenue\n",
      "Devon St & Mt. Pleasant Ave => Devon St & Mt. Pleasant Avenue\n",
      "S. Clinton Ave => S. Clinton Avenue\n",
      "Essington Ave => Essington Avenue\n",
      "Sharon Ave => Sharon Avenue\n",
      "Montgomery Ave => Montgomery Avenue\n",
      "Grays Ave => Grays Avenue\n",
      "S Clinton Ave => S Clinton Avenue\n",
      "Penrose Ave => Penrose Avenue\n",
      "West Huntington Ave => West Huntington Avenue\n",
      "Mt.Ephraim Ave => Mt.Ephraim Avenue\n",
      "N Olden Ave => N Olden Avenue\n",
      "Hirst Ave => Hirst Avenue\n",
      "Summit Ave => Summit Avenue\n",
      "Towamencin Ave => Towamencin Avenue\n",
      "Washington Ave => Washington Avenue\n",
      "Chester Ave => Chester Avenue\n",
      "Constitution Ave => Constitution Avenue\n",
      "72nd Ave and Orgontz Ave => 72nd Ave and Orgontz Avenue\n",
      "E. Mt Airy Ave => E. Mt Airy Avenue\n",
      "Parkway Ave => Parkway Avenue\n",
      "Stenton Ave => Stenton Avenue\n",
      "W Chelten Ave => W Chelten Avenue\n",
      "West Butler Ave => West Butler Avenue\n",
      "Bryn Mawr Ave => Bryn Mawr Avenue\n",
      "Philmont Ave => Philmont Avenue\n",
      "West Glenside Ave => West Glenside Avenue\n",
      "Park Ave => Park Avenue\n",
      "Cottman Ave => Cottman Avenue\n",
      "West Trenton Ave => West Trenton Avenue\n",
      "East Lancaster Ave => East Lancaster Avenue\n",
      "West Mermaid Lane and Germantown Ave => West Mermaid Lane and Germantown Avenue\n",
      "West Girard Ave => West Girard Avenue\n",
      "Bishop Ave, Clifton Ave => Bishop Ave, Clifton Avenue\n",
      "East Wadsworth Ave => East Wadsworth Avenue\n",
      "S Washington Ave => S Washington Avenue\n",
      "Shawmont & Nixon => Shawmont & Nixon\n",
      "Chestnut Street #902 => Chestnut Street #902\n",
      "Greene => Greene\n",
      "Henry Ave #D102 => Henry Ave #D102\n",
      "200 Manor Ave. Langhorne, PA 19047 => 200 Manor Ave. Langhorne, PA 19047\n",
      "2275 E Lincoln Hwy, Langhorne, PA 19047 => 2275 E Lincoln Hwy, Langhorne, PA 19047\n",
      "2245 E. Lincoln Hwy, Langhorne, PA 19047 => 2245 E. Lincoln Hwy, Langhorne, PA 19047\n",
      "2300  East Lincoln Highway, Pennsylvania 19047 => 2300  East Lincoln Highway, Pennsylvania 19047\n",
      "12th and Vine => 12th and Vine\n",
      "Mallon => Mallon\n",
      "Spruce => Spruce\n",
      "EDGMONT AVE => EDGMONT AVE\n",
      "Newtown-Langhorne road => Newtown-Langhorne Road\n",
      "Morehall road => Morehall Road\n",
      "Salina => Salina\n",
      "NJ 70 W => NJ 70 W\n",
      "NJ-73 => NJ-73\n",
      "S. 15th St. => S. 15th Street\n",
      "Almond St. => Almond Street\n",
      "W. State St. => W. State Street\n",
      "N 24th St. => N 24th Street\n",
      "South Broad St. => South Broad Street\n",
      "Mt. Pleasant Ave, Devon St, Sprague St. => Mt. Pleasant Ave, Devon St, Sprague Street\n",
      "12th St. => 12th Street\n",
      "Diamond St. => Diamond Street\n",
      "S. 40th St. => S. 40th Street\n",
      "E. State St. => E. State Street\n",
      "Haverford => Haverford\n",
      "N 39th => N 39th\n",
      "Winston Way => Winston Way\n",
      "Scout Way => Scout Way\n",
      "Technology Way => Technology Way\n",
      "Veteran's Way => Veteran's Way\n",
      "Mather Way => Mather Way\n",
      "Westtown Way => Westtown Way\n",
      "Braxton Way => Braxton Way\n",
      "Jennifer Way => Jennifer Way\n",
      "Woodview Way => Woodview Way\n",
      "Janton Way => Janton Way\n",
      "Nina Way => Nina Way\n",
      "Green Valley Way => Green Valley Way\n",
      "Arbor Way => Arbor Way\n",
      "Azalea Way => Azalea Way\n",
      "Eagle Way => Eagle Way\n",
      "Plaza Way => Plaza Way\n",
      "Lafrance Way => Lafrance Way\n",
      "Applied Card Way => Applied Card Way\n",
      "Johnnys Way => Johnnys Way\n",
      "Rock Way => Rock Way\n",
      "Bellows Way => Bellows Way\n",
      "Lucretia Mott Way => Lucretia Mott Way\n",
      "Lantern Way => Lantern Way\n",
      "Triumphe Way => Triumphe Way\n",
      "Lakeview Drive North => Lakeview Drive North\n",
      "Kings Highway North => Kings Highway North\n",
      "Delsea Drive North => Delsea Drive North\n",
      "E. State st. => E. State st.\n",
      "US-130 => US-130\n",
      "117 South 18th StreetPhiladelphia => 117 South 18th StreetPhiladelphia\n",
      "W Ridge Pike #651 => W Ridge Pike #651\n",
      "Brookline Blvd. => Brookline Blvd.\n",
      "mortgage way => mortgage way\n",
      "North Hutchinson => North Hutchinson\n",
      "Johnston St => Johnston Street\n",
      "Green St => Green Street\n",
      "Spring Garden St => Spring Garden Street\n",
      "Quarry St => Quarry Street\n",
      "S Broad St => S Broad Street\n",
      "W State St => W State Street\n",
      "S Norwood St => S Norwood Street\n",
      "S 22nd St => S 22nd Street\n",
      "Dickinson St => Dickinson Street\n",
      "Dekalb St => Dekalb Street\n",
      "Ranstead St => Ranstead Street\n",
      "S 4th St => S 4th Street\n",
      "E State St => E State Street\n",
      "Washington St => Washington Street\n",
      "South St Bernard St => South St Bernard Street\n",
      "Market St => Market Street\n",
      "S 19th St => S 19th Street\n",
      "46th and Market St => 46th and Market Street\n",
      "E. Passyunk Ave and Kauffman St => E. Passyunk Ave and Kauffman Street\n",
      "N 6th St => N 6th Street\n",
      "S 50th St => S 50th Street\n",
      "N Gratz St => N Gratz Street\n",
      "S Warren St => S Warren Street\n",
      "S 3rd St => S 3rd Street\n",
      "N 5th St => N 5th Street\n",
      "N 3rd St => N 3rd Street\n",
      "S Main St => S Main Street\n",
      "Chestnut St => Chestnut Street\n",
      "Rhawn St => Rhawn Street\n",
      "E Penn St => E Penn Street\n",
      "Coates St => Coates Street\n",
      "West Main St => West Main Street\n",
      "Baring St => Baring Street\n",
      "South St => South Street\n",
      "E Wingohocking St => E Wingohocking Street\n",
      "N 4th St => N 4th Street\n",
      "South Bancroft St => South Bancroft Street\n",
      "Center St => Center Street\n",
      "E Hector St => E Hector Street\n",
      "Race St => Race Street\n",
      "Starr St => Starr Street\n",
      "E Front St => E Front Street\n",
      "Federal St => Federal Street\n",
      "South 40th St => South 40th Street\n",
      "Front St & Tasker St => Front St & Tasker Street\n",
      "Carson St => Carson Street\n",
      "North Front St => North Front Street\n",
      "S 20th St => S 20th Street\n",
      "507 E Tulpehocken St => 507 E Tulpehocken Street\n",
      "Walnut St => Walnut Street\n",
      "Cooper St => Cooper Street\n",
      "S 28th St => S 28th Street\n",
      "S 47th St => S 47th Street\n",
      "S 41st St => S 41st Street\n",
      "North Broad St => North Broad Street\n",
      "St John St => St John Street\n",
      "Bush St => Bush Street\n",
      "N Main St => N Main Street\n",
      "N Broad St => N Broad Street\n",
      "S 24th St => S 24th Street\n",
      "E Hampton St => E Hampton Street\n",
      "McKean St => McKean Street\n",
      "State Route 38 => State Route 38\n",
      "Route 38 => Route 38\n",
      "New Jersey 38 => New Jersey 38\n",
      "Marlton Pike East Ste. 168 => Marlton Pike East Ste. 168\n",
      "South 18th Steet => South 18th Street\n",
      "West king => West king\n",
      "Kagey Rd. => Kagey Road\n",
      "S. Chester Rd. => S. Chester Road\n",
      "W. Street Rd. => W. Street Road\n",
      "North Lewis Rd. => North Lewis Road\n",
      "Clements Bridge Rd. => Clements Bridge Road\n",
      "Wistar Rd. => Wistar Road\n",
      "York Rd. => York Road\n",
      "N. Lewis Rd. => N. Lewis Road\n",
      "N Preston => N Preston\n",
      "North 13th and Brown Streets => North 13th and Brown Streets\n",
      "Locust Walk => Locust Walk\n",
      "Polett Walk => Polett Walk\n",
      "Woodland Walk => Woodland Walk\n",
      "Liacouras Walk => Liacouras Walk\n",
      "Hamilton Walk => Hamilton Walk\n",
      "33 => 33\n",
      "Route 33 => Route 33\n",
      "Heaver Close => Heaver Close\n",
      "Greenview Ter => Greenview Terrace\n",
      "Market => Market\n",
      "Portsmouth Ct => Portsmouth Court\n",
      "4080 => 4080\n",
      "Race Street 2nd Floor => Race Street 2nd Floor\n",
      "Simpkins Ln => Simpkins Lane\n",
      "Patricia Ln => Patricia Lane\n",
      "pullen al => pullen al\n",
      "Sletcher and Thompson => Sletcher and Thompson\n",
      "michigan ave => michigan Avenue\n",
      "and 1891 brunswick ave => and 1891 brunswick Avenue\n",
      "Ridge ave => Ridge Avenue\n",
      "hillcrest ave => hillcrest Avenue\n",
      "N 43rd => N 43rd\n",
      "Town Center => Town Center\n",
      "North Independence Mall East => North Independence Mall East\n",
      "South Independence Mall East => South Independence Mall East\n",
      "Route 38 East => Route 38 East\n",
      "Clementon Road East => Clementon Road East\n",
      "Lincoln Drive East => Lincoln Drive East\n",
      "High Street East => High Street East\n",
      "Marlton Pike East => Marlton Pike East\n",
      "Cabot Boulevard East => Cabot Boulevard East\n",
      "North Independence Ml East => North Independence Ml East\n",
      "Kings Highway East => Kings Highway East\n",
      "Spring Garden => Spring Garden\n",
      "Brynwood Manor => Brynwood Manor\n",
      "Rt 40 => Rt 40\n",
      "1140 US Highway 40 => 1140 US Highway 40\n",
      "Route 1 => Route 1\n",
      "S Newtown Street Rd #1 => S Newtown Street Rd #1\n",
      "Walnut St #1 => Walnut St #1\n",
      "Easton Rd #1 => Easton Rd #1\n",
      "West Girard Avenue, 5 => West Girard Avenue, 5\n",
      "Lincoln Hwy => Lincoln Highway\n",
      "Harding Hwy => Harding Highway\n",
      "Tommy's Meadow Dr => Tommy's Meadow Drive\n",
      "Deerpath Dr => Deerpath Drive\n",
      "Merrill Lynch Dr => Merrill Lynch Drive\n",
      "2515 Metropolitan Dr => 2515 Metropolitan Drive\n",
      "Revere Dr => Revere Drive\n",
      "S Bethlehem Pike #A => S Bethlehem Pike #A\n",
      "Office Center Dr #205 => Office Center Dr #205\n",
      "US 206 => US 206\n",
      "US 70 & US 206 => US 70 & US 206\n",
      "Bridge Sreet => Bridge Street\n",
      "Easton Road Route 611 => Easton Road Route 611\n",
      "Bigler => Bigler\n",
      "New Jersey 73 => New Jersey 73\n",
      "Route 73 => Route 73\n",
      "State Route 73 => State Route 73\n",
      "North Route 73 => North Route 73\n",
      "US 70 => US 70\n",
      "State Route 70 => State Route 70\n",
      "Painters Crossing => Painters Crossing\n",
      "Harpers Crossing => Harpers Crossing\n",
      "Lakeview Drive South => Lakeview Drive South\n",
      "Steel Road South => Steel Road South\n",
      "Route 130 South => Route 130 South\n",
      "country club lane => country club Lane\n",
      "S. 41st => S. 41st\n",
      "Bucks Town drive => Bucks Town Drive\n",
      "pear st => pear Street\n",
      "s broad st => s broad Street\n",
      "jackson st => jackson Street\n",
      "s 3rd st => s 3rd Street\n",
      "s warren st => s warren Street\n",
      "w state st => w state Street\n",
      "livingston st => livingston Street\n",
      "centre st => centre Street\n",
      "s stockton st => s stockton Street\n",
      "e state st => e state Street\n",
      "mercer st => mercer Street\n",
      "e front st => e front Street\n",
      "clay st => clay Street\n",
      "market st => market Street\n",
      "s montgomery st => s montgomery Street\n",
      "Main st => Main Street\n",
      "brunswick ave ext => brunswick ave Exit\n",
      "Route 130 south => Route 130 south\n",
      "Nassau Parl Blvd => Nassau Parl Boulevard\n",
      "Centennial Blvd => Centennial Boulevard\n",
      "Nassau Park Blvd => Nassau Park Boulevard\n",
      "Brookline Blvd => Brookline Boulevard\n",
      "Floral Vale Blvd => Floral Vale Boulevard\n",
      "Garden Gold Blvd => Garden Gold Boulevard\n",
      "Hearthstone Blvd => Hearthstone Boulevard\n",
      "W Cuthbert Blvd => W Cuthbert Boulevard\n",
      "Garden Golf Blvd => Garden Golf Boulevard\n",
      "Shannondell Blvd => Shannondell Boulevard\n",
      "S Christopher Columbus Blvd => S Christopher Columbus Boulevard\n",
      "South Maple => South Maple\n"
     ]
    }
   ],
   "source": [
    "def update_name(name, mapping, regex):\n",
    "    m = regex.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type in mapping:\n",
    "            name = re.sub(regex, mapping[street_type], name)\n",
    "    return name\n",
    "\n",
    "for street_type, ways in philly_street_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping, street_type_re)\n",
    "        print name, \"=>\", better_name # update street names using better name \n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### I reused some code snippets from the street abbrevation function earlier in this project to check for correct uniform zip codes in the data file. Below is my code for auditing zip codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'08': set(['08002',\n",
      "            '08003',\n",
      "            '08009',\n",
      "            '08010',\n",
      "            '08012',\n",
      "            '08021',\n",
      "            '08026',\n",
      "            '08028',\n",
      "            '08030',\n",
      "            '08031',\n",
      "            '08033',\n",
      "            '08033-2001',\n",
      "            '08034',\n",
      "            '08035',\n",
      "            '08037',\n",
      "            '08043',\n",
      "            '08046',\n",
      "            '08048',\n",
      "            '08051',\n",
      "            '08052',\n",
      "            '08053',\n",
      "            '08054',\n",
      "            '08055',\n",
      "            '08057',\n",
      "            '08060',\n",
      "            '08061',\n",
      "            '08062',\n",
      "            '08062-4446',\n",
      "            '08063',\n",
      "            '08065',\n",
      "            '08066',\n",
      "            '08068',\n",
      "            '08069',\n",
      "            '08070',\n",
      "            '08071',\n",
      "            '08077',\n",
      "            '08080',\n",
      "            '08081',\n",
      "            '08084',\n",
      "            '08085',\n",
      "            '08086',\n",
      "            '08088',\n",
      "            '08091',\n",
      "            '08094',\n",
      "            '08096',\n",
      "            '08097',\n",
      "            '08098',\n",
      "            '08102',\n",
      "            '08103',\n",
      "            '08105',\n",
      "            '08106',\n",
      "            '08107',\n",
      "            '08108',\n",
      "            '08109',\n",
      "            '08110',\n",
      "            '0815',\n",
      "            '08343',\n",
      "            '08505',\n",
      "            '08515',\n",
      "            '08534',\n",
      "            '08540',\n",
      "            '08609',\n",
      "            '08610',\n",
      "            '08611',\n",
      "            '08618',\n",
      "            '08619',\n",
      "            '08628',\n",
      "            '08648',\n",
      "            '08690',\n",
      "            '08850']),\n",
      " '17': set(['1713', '1719', '1723']),\n",
      " '18': set(['18194',\n",
      "            '18901',\n",
      "            '18914',\n",
      "            '18925',\n",
      "            '18929',\n",
      "            '18936',\n",
      "            '18940',\n",
      "            '189440',\n",
      "            '18954',\n",
      "            '18956',\n",
      "            '18964',\n",
      "            '18966',\n",
      "            '18974',\n",
      "            '18976']),\n",
      " '19': set(['19001',\n",
      "            '19002',\n",
      "            '19003',\n",
      "            '19004',\n",
      "            '19006',\n",
      "            '19007',\n",
      "            '19008',\n",
      "            '19010',\n",
      "            '19010-3224',\n",
      "            '19012',\n",
      "            '19013',\n",
      "            '19014',\n",
      "            '19015',\n",
      "            '19016',\n",
      "            '19018',\n",
      "            '19020',\n",
      "            '19025',\n",
      "            '19027',\n",
      "            '19029',\n",
      "            '19030',\n",
      "            '19030-4005',\n",
      "            '19031',\n",
      "            '19033',\n",
      "            '19034',\n",
      "            '19035',\n",
      "            '19036',\n",
      "            '19038',\n",
      "            '19040',\n",
      "            '19041',\n",
      "            '19041-1228',\n",
      "            '19044',\n",
      "            '19046',\n",
      "            '19047',\n",
      "            '19050',\n",
      "            '19052',\n",
      "            '19053',\n",
      "            '19054',\n",
      "            '19055',\n",
      "            '19057',\n",
      "            '19060',\n",
      "            '19061',\n",
      "            '19063',\n",
      "            '19064',\n",
      "            '19066',\n",
      "            '19067',\n",
      "            '19070',\n",
      "            '19072',\n",
      "            '19072b1393e',\n",
      "            '19073',\n",
      "            '19073-3299',\n",
      "            '19074',\n",
      "            '19075',\n",
      "            '19076',\n",
      "            '19078',\n",
      "            '19079',\n",
      "            '19081',\n",
      "            '19082',\n",
      "            '19083',\n",
      "            '19085',\n",
      "            '19086',\n",
      "            '19087',\n",
      "            '19087-3696',\n",
      "            '19090',\n",
      "            '19095',\n",
      "            '19096',\n",
      "            '19096-9998',\n",
      "            '19102',\n",
      "            '19103',\n",
      "            '19104',\n",
      "            '19104-2989',\n",
      "            '19105',\n",
      "            '19106',\n",
      "            '19107',\n",
      "            '19109',\n",
      "            '19111',\n",
      "            '19112',\n",
      "            '19114',\n",
      "            '19115',\n",
      "            '19116',\n",
      "            '19118',\n",
      "            '19119',\n",
      "            '19120',\n",
      "            '19121',\n",
      "            '19122',\n",
      "            '19123',\n",
      "            '19124',\n",
      "            '19125',\n",
      "            '19126',\n",
      "            '19127',\n",
      "            '19128',\n",
      "            '19129',\n",
      "            '19130',\n",
      "            '19131',\n",
      "            '19132',\n",
      "            '19133',\n",
      "            '19134',\n",
      "            '19135',\n",
      "            '19136',\n",
      "            '19137',\n",
      "            '19138',\n",
      "            '19139',\n",
      "            '19140',\n",
      "            '19141',\n",
      "            '19142',\n",
      "            '19143',\n",
      "            '19144',\n",
      "            '19145',\n",
      "            '19146',\n",
      "            '19147',\n",
      "            u'19147\\u200e',\n",
      "            '19148',\n",
      "            '19148-9996',\n",
      "            '19149',\n",
      "            '19150',\n",
      "            '19151',\n",
      "            '19152',\n",
      "            '19153',\n",
      "            '19154',\n",
      "            '19154-3131',\n",
      "            '19301',\n",
      "            '19312',\n",
      "            '19312-1239',\n",
      "            '19314',\n",
      "            '19317',\n",
      "            '19333',\n",
      "            '19341',\n",
      "            '19342',\n",
      "            '19355',\n",
      "            '19380',\n",
      "            '19382',\n",
      "            '19401',\n",
      "            '19403',\n",
      "            '19405',\n",
      "            '19406',\n",
      "            '19422',\n",
      "            '19426',\n",
      "            '19428',\n",
      "            '19438',\n",
      "            '19440',\n",
      "            '19443',\n",
      "            '19444',\n",
      "            '19446',\n",
      "            '19454',\n",
      "            '19456',\n",
      "            '19460',\n",
      "            '19462',\n",
      "            '19464',\n",
      "            '19468',\n",
      "            '19473',\n",
      "            '19474',\n",
      "            '19477',\n",
      "            '19478',\n",
      "            '19703',\n",
      "            '19720',\n",
      "            '19801',\n",
      "            '19802',\n",
      "            '19803',\n",
      "            '19803-9997',\n",
      "            '19805',\n",
      "            '19806',\n",
      "            '19809',\n",
      "            '19810']),\n",
      " '51': set(['519 Stokes Rd # A Medford, NJ 08055']),\n",
      " '60': set(['601 Stokes Road Medford, NJ 08055']),\n",
      " '61': set(['617 Stokes Rd # 10 Medford, NJ 08055',\n",
      "            '617 Stokes Road Medford, NJ 08055']),\n",
      " '62': set(['620 Stokes Rd # EMedford, NJ 08055']),\n",
      " '94': set(['9406', '94706']),\n",
      " 'NJ': set(['NJ 08033', 'NJ 08083', 'NJ 08107']),\n",
      " 'PA': set(['PA', 'PA 19153', 'PA 19428', 'PA 19446']),\n",
      " 'Ph': set(['Philadelphia, PA 19134'])}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict # add imports to python code \n",
    "\n",
    "def audit_zipcode(invalid_zipcodes, zipcode):\n",
    "    twoDigits = zipcode[0:2]\n",
    "    \n",
    "    if not twoDigits.isdigit():\n",
    "        invalid_zipcodes[twoDigits].add(zipcode)\n",
    "    \n",
    "    elif twoDigits != 95:\n",
    "        invalid_zipcodes[twoDigits].add(zipcode)\n",
    "        \n",
    "def is_zipcode(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\") \n",
    "\"\"\"look for k attribute tags with addr:postcode format to audit\"\"\" \n",
    "\n",
    "def audit_zip(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    invalid_zipcodes = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)): # start auditing \n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\": # allocating correct areas for audit \n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_zipcode(tag):\n",
    "                    audit_zipcode(invalid_zipcodes,tag.attrib['v'])\n",
    "\n",
    "    return invalid_zipcodes\n",
    "\n",
    "philly_zipcode = audit_zip(OSM_FILE) # run audit_zip funtion against OSM_FILE \n",
    "pprint.pprint(dict(philly_zipcode)) ##pprint output from zipcodes in file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The code block below returns all updated zip-codes from the OSM file'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"The code block below returns all updated zip-codes from the OSM file\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NJ 08033 => 08033\n",
      "NJ 08083 => 08083\n",
      "NJ 08107 => 08107\n",
      "1713 => Invalid\n",
      "1719 => Invalid\n",
      "1723 => Invalid\n",
      "19810 => 19810\n",
      "19014 => 19014\n",
      "19015 => 19015\n",
      "19016 => 19016\n",
      "19010 => 19010\n",
      "19012 => 19012\n",
      "19013 => 19013\n",
      "19018 => 19018\n",
      "19317 => 19317\n",
      "19803-9997 => 19803-9997\n",
      "19314 => 19314\n",
      "19312 => 19312\n",
      "19087-3696 => 19087-3696\n",
      "19406 => 19406\n",
      "19405 => 19405\n",
      "19151 => 19151\n",
      "19150 => 19150\n",
      "19401 => 19401\n",
      "19152 => 19152\n",
      "19468 => 19468\n",
      "19464 => 19464\n",
      "19460 => 19460\n",
      "19462 => 19462\n",
      "19061 => 19061\n",
      "19060 => 19060\n",
      "19063 => 19063\n",
      "19064 => 19064\n",
      "19067 => 19067\n",
      "19066 => 19066\n",
      "19380 => 19380\n",
      "19382 => 19382\n",
      "19073-3299 => 19073-3299\n",
      "19301 => 19301\n",
      "19010-3224 => 19010-3224\n",
      "19148 => 19148\n",
      "19149 => 19149\n",
      "19146 => 19146\n",
      "19147 => 19147\n",
      "19144 => 19144\n",
      "19145 => 19145\n",
      "19147‎ => 19147\n",
      "19143 => 19143\n",
      "19140 => 19140\n",
      "19141 => 19141\n",
      "19478 => 19478\n",
      "19477 => 19477\n",
      "19474 => 19474\n",
      "19473 => 19473\n",
      "19072 => 19072\n",
      "19073 => 19073\n",
      "19070 => 19070\n",
      "19076 => 19076\n",
      "19074 => 19074\n",
      "19075 => 19075\n",
      "19078 => 19078\n",
      "19079 => 19079\n",
      "19703 => 19703\n",
      "19355 => 19355\n",
      "19443 => 19443\n",
      "19072b1393e => 19072\n",
      "19312-1239 => 19312-1239\n",
      "19440 => 19440\n",
      "19446 => 19446\n",
      "19444 => 19444\n",
      "19104-2989 => 19104-2989\n",
      "19047 => 19047\n",
      "19142 => 19142\n",
      "19044 => 19044\n",
      "19041-1228 => 19041-1228\n",
      "19041 => 19041\n",
      "19040 => 19040\n",
      "19119 => 19119\n",
      "19341 => 19341\n",
      "19342 => 19342\n",
      "19096-9998 => 19096-9998\n",
      "19111 => 19111\n",
      "19112 => 19112\n",
      "19115 => 19115\n",
      "19114 => 19114\n",
      "19116 => 19116\n",
      "19050 => 19050\n",
      "19118 => 19118\n",
      "19052 => 19052\n",
      "19053 => 19053\n",
      "19054 => 19054\n",
      "19055 => 19055\n",
      "19057 => 19057\n",
      "19333 => 19333\n",
      "19148-9996 => 19148-9996\n",
      "19154 => 19154\n",
      "19102 => 19102\n",
      "19103 => 19103\n",
      "19106 => 19106\n",
      "19107 => 19107\n",
      "19104 => 19104\n",
      "19105 => 19105\n",
      "19403 => 19403\n",
      "19109 => 19109\n",
      "19454 => 19454\n",
      "19456 => 19456\n",
      "19029 => 19029\n",
      "19153 => 19153\n",
      "19046 => 19046\n",
      "19025 => 19025\n",
      "19027 => 19027\n",
      "19020 => 19020\n",
      "19083 => 19083\n",
      "19082 => 19082\n",
      "19081 => 19081\n",
      "19087 => 19087\n",
      "19086 => 19086\n",
      "19085 => 19085\n",
      "19154-3131 => 19154-3131\n",
      "19139 => 19139\n",
      "19138 => 19138\n",
      "19137 => 19137\n",
      "19136 => 19136\n",
      "19135 => 19135\n",
      "19134 => 19134\n",
      "19133 => 19133\n",
      "19132 => 19132\n",
      "19131 => 19131\n",
      "19130 => 19130\n",
      "19422 => 19422\n",
      "19038 => 19038\n",
      "19426 => 19426\n",
      "19036 => 19036\n",
      "19428 => 19428\n",
      "19034 => 19034\n",
      "19035 => 19035\n",
      "19033 => 19033\n",
      "19030 => 19030\n",
      "19031 => 19031\n",
      "19095 => 19095\n",
      "19096 => 19096\n",
      "19090 => 19090\n",
      "19720 => 19720\n",
      "19803 => 19803\n",
      "19802 => 19802\n",
      "19801 => 19801\n",
      "19806 => 19806\n",
      "19805 => 19805\n",
      "19809 => 19809\n",
      "19438 => 19438\n",
      "19128 => 19128\n",
      "19129 => 19129\n",
      "19120 => 19120\n",
      "19121 => 19121\n",
      "19122 => 19122\n",
      "19123 => 19123\n",
      "19124 => 19124\n",
      "19125 => 19125\n",
      "19126 => 19126\n",
      "19127 => 19127\n",
      "19008 => 19008\n",
      "19003 => 19003\n",
      "19002 => 19002\n",
      "19001 => 19001\n",
      "19030-4005 => 19030-4005\n",
      "19007 => 19007\n",
      "19006 => 19006\n",
      "19004 => 19004\n",
      "18940 => 18940\n",
      "18936 => 18936\n",
      "18956 => 18956\n",
      "18954 => 18954\n",
      "18966 => 18966\n",
      "18194 => 18194\n",
      "18964 => 18964\n",
      "18974 => 18974\n",
      "18976 => 18976\n",
      "18929 => 18929\n",
      "189440 => 18944\n",
      "18914 => 18914\n",
      "18901 => 18901\n",
      "18925 => 18925\n",
      "08106 => 08106\n",
      "08028 => 08028\n",
      "08009 => 08009\n",
      "08055 => 08055\n",
      "08021 => 08021\n",
      "08091 => 08091\n",
      "08690 => 08690\n",
      "08534 => 08534\n",
      "08003 => 08003\n",
      "08002 => 08002\n",
      "08085 => 08085\n",
      "08628 => 08628\n",
      "08086 => 08086\n",
      "08081 => 08081\n",
      "08080 => 08080\n",
      "08103 => 08103\n",
      "08088 => 08088\n",
      "08052 => 08052\n",
      "08084 => 08084\n",
      "08648 => 08648\n",
      "08850 => 08850\n",
      "08515 => 08515\n",
      "08034 => 08034\n",
      "08035 => 08035\n",
      "08609 => 08609\n",
      "08037 => 08037\n",
      "08030 => 08030\n",
      "08505 => 08505\n",
      "08054 => 08054\n",
      "08343 => 08343\n",
      "08070 => 08070\n",
      "08071 => 08071\n",
      "08031 => 08031\n",
      "08110 => 08110\n",
      "08069 => 08069\n",
      "08057 => 08057\n",
      "08046 => 08046\n",
      "08012 => 08012\n",
      "08062-4446 => 08062-4446\n",
      "08010 => 08010\n",
      "08540 => 08540\n",
      "08096 => 08096\n",
      "08053 => 08053\n",
      "08094 => 08094\n",
      "08066 => 08066\n",
      "08098 => 08098\n",
      "08026 => 08026\n",
      "08033 => 08033\n",
      "08051 => 08051\n",
      "08610 => 08610\n",
      "08611 => 08611\n",
      "08097 => 08097\n",
      "08063 => 08063\n",
      "08033-2001 => 08033-2001\n",
      "08618 => 08618\n",
      "08619 => 08619\n",
      "08109 => 08109\n",
      "08105 => 08105\n",
      "08043 => 08043\n",
      "08107 => 08107\n",
      "0815 => Invalid\n",
      "08102 => 08102\n",
      "08068 => 08068\n",
      "08048 => 08048\n",
      "08065 => 08065\n",
      "08077 => 08077\n",
      "08108 => 08108\n",
      "08062 => 08062\n",
      "08061 => 08061\n",
      "08060 => 08060\n",
      "519 Stokes Rd # A Medford, NJ 08055 => 08055\n",
      "601 Stokes Road Medford, NJ 08055 => 08055\n",
      "617 Stokes Rd # 10 Medford, NJ 08055 => 08055\n",
      "617 Stokes Road Medford, NJ 08055 => 08055\n",
      "620 Stokes Rd # EMedford, NJ 08055 => 08055\n",
      "PA 19153 => 19153\n",
      "PA => Invalid\n",
      "PA 19446 => 19446\n",
      "PA 19428 => 19428\n",
      "Philadelphia, PA 19134 => 19134\n",
      "94706 => 94706\n",
      "9406 => Invalid\n"
     ]
    }
   ],
   "source": [
    "import re #imports reg expressions into python\n",
    "def update_zip(user_entry):\n",
    "    \"\"\"create update_zip function to begin updating zip-codes in file\"\"\"\n",
    "    zipcodes_in_entry = re.findall(r'(\\d{5}(-\\d{4})?)', user_entry)\n",
    "\n",
    "    if len(zipcodes_in_entry) > 0: \n",
    "        return zipcodes_in_entry[0][0]\n",
    "    else:\n",
    "        return 'Invalid'\n",
    "\n",
    "for street_type, ways in philly_zipcode.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_zip(name)\n",
    "        print name, \"=>\", better_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Preparing the data set for MongoDB manipulation by converting XML  to JSON'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Preparing the data set for MongoDB manipulation by converting XML  to JSON\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "postal_codes = re.compile(r'^[ABCEGHJKLMNPRSTVXY][0-9][ABCEGHJKLMNPRSTVWXYZ][\\s]?[0-9][ABCEGHJKLMNPRSTVWXYZ][0-9]')\n",
    "street_types = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "OSM_FILE = \"/Users/aliciadale/Desktop/philadelphia_pennsylvania.osm\"\n",
    "\n",
    "CREATED = [\"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "\n",
    "expected = [\"Avenue\", \"Boulevard\", \"Court\", \"Circle\", \"Drive\", \"Exit\", \"Highway\", \"Lane\",\n",
    "            \"Parkway\", \"Pike\", \"Place\", \"Road\", \"Square\", \"Suite\", \"Street\", \"Trail\", \"Terrace\"]\n",
    "\n",
    "'''the above \"expected\" variable contains all of the full words that can be contained in an address in my file\n",
    "the below \"mapping\" variable contains all of the mistake abbreviations that have been used in my OSM file and \n",
    "shows their proper format'''\n",
    "\n",
    "\n",
    "street_mapping = { \"Av\" : \"Avenue\",\n",
    "            \"avenue\" : \"Avenue\",\n",
    "            \"Ave\" : \"Avenue\",\n",
    "            \"Ave.\" : \"Avenue\",\n",
    "            \"ave\" : \"Avenue\",\n",
    "            \"Blvd\" : \"Boulevard\",\n",
    "            \"Crt\" : \"Court\",\n",
    "            \"Ct\" : \"Court\",\n",
    "            \"Cir\" : \"Circle\",\n",
    "            \"Dr\" : \"Drive\",\n",
    "            \"drive\" : \"Drive\",\n",
    "            \"Ext\" : \"Exit\",\n",
    "            \"ext\" : \"Exit\",\n",
    "            \"lane\" : \"Lane\",\n",
    "            \"Ln\" : \"Lane\",\n",
    "            \"PIke\" : \"Pike\",\n",
    "            \"Rd\" : \"Road\",\n",
    "            \"Rd.\" : \"Road\",\n",
    "            \"rd\" : \"Road\",\n",
    "            \"road\" : \"Road\",\n",
    "            \"Hwy\" : \"Highway\",\n",
    "            \"Sreet\" : \"Street\",\n",
    "            \"st\" : \"Street\", \n",
    "            \"ST\" : \"Street\",\n",
    "            \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Atreet\" : \"Street\",\n",
    "            \"Sstreet\" : \"Street\",\n",
    "            \"street\" : \"Street\",\n",
    "            \"Steet\" : \"Street\",\n",
    "            \"Sq\" : \"Square\",\n",
    "            \"Ste\" : \"Suite\",\n",
    "           \"Trl\" : \"Trail\",\n",
    "            \"Ter\" : \"Terrace\"}\n",
    "\n",
    "def shape_element(element):\n",
    "    \"\"\"Parses element from iterparse, cleans address, and returns dictionary\"\"\"\n",
    "    node = {}\n",
    "    if element.tag == \"way\":\n",
    "    \t  node['node_refs'] = []\n",
    "    if element.tag == \"node\" or element.tag == \"way\":\n",
    "        node['type'] = element.tag\n",
    "        attrs = element.attrib \n",
    "        node['created'] = {}\n",
    "        for attr in attrs: \n",
    "            if attr == \"lat\" or attr == \"lon\":\n",
    "                if 'pos' not in node:\n",
    "                    node['pos'] = []\n",
    "                if attr == 'lat':\n",
    "                    node['pos'].insert(0,float(element.attrib[attr]))\n",
    "                elif attr == 'lon':\n",
    "                    node['pos'].insert(1,float(element.attrib[attr]))\n",
    "            elif attr in CREATED:\n",
    "        \t    node['created'][attr] = element.attrib[attr]\n",
    "            else:\n",
    "                node[attr] = element.attrib[attr]    \n",
    "        for subtag in element.iter('tag'):\n",
    "            key, value = subtag.attrib['k'], subtag.attrib['v']\n",
    "            if problemchars.match(key):\n",
    "                continue\n",
    "            elif lower_colon.match(key):\n",
    "                subtagjsonkey = key.split(':')\n",
    "                if subtagjsonkey[0] == 'addr':\n",
    "                    if 'address' not in node:\n",
    "                    \t  node['address'] = {}\n",
    "                    if subtagjsonkey[1] == 'street':\n",
    "                        node['address'][subtagjsonkey[1]] = update_name(value, mapping)\n",
    "                    elif subtagjsonkey[1] == 'postcode':\n",
    "                        node['address'][subtagjsonkey[1]] = update_postcode(value)\n",
    "                elif subtagjsonkey[0] == 'turn':\n",
    "                    continue\n",
    "                else:\n",
    "                    node[subtagjsonkey[1]] = value             \n",
    "            else:\n",
    "                if ':' not in key:\n",
    "                    if key == \"exit_to\":\n",
    "                        node[key] = update_name(value, mapping)\n",
    "                    else:\n",
    "                        node[key] = value\n",
    "        if element.tag == \"way\":                    \n",
    "            for subtag in element.iter('nd'):\n",
    "                node['node_refs'].append(subtag.attrib['ref'])      \n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n",
    "\n",
    "    data = process_map('OSM_FILE', True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Add import for MongoDB by using pymongo, and connecting to MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import signal\n",
    "import os\n",
    "import subprocess\n",
    "pro = subprocess.Popen('mongod', preexec_fn = os.setsid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "db_name = 'openstreetmap'\n",
    "\n",
    "# Connect to Mongo DB\n",
    "client = MongoClient('localhost:27017')\n",
    "db = client[db_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: mongoimport -h 127.0.0.1:27017 --db openstreetmap --collection /Users/aliciadale/Desktop/philadelphia_pennsylvania --file /Users/aliciadale/Desktop/philadelphia_pennsylvania.osm.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Build mongoimport command instead of using homebrew\"\"\"\n",
    "collection = OSM_FILE[:OSM_FILE.find('.')]\n",
    "json_file =  OSM_FILE + '.json'\n",
    "\n",
    "mongoimport_cmd = 'mongoimport -h 127.0.0.1:27017 ' + \\\n",
    "                  '--db ' + db_name + \\\n",
    "                  ' --collection ' + collection + \\\n",
    "                  ' --file ' + json_file\n",
    "\n",
    "\"\"\"Before importing, drop collection if it is already running\"\"\"\n",
    "if collection in db.collection_names():\n",
    "    print 'Dropping collection: ' + collection\n",
    "    db[collection].drop()\n",
    "    \n",
    "\"\"\"Execute the command\"\"\"\n",
    "print 'Executing: ' + mongoimport_cmd\n",
    "subprocess.call(mongoimport_cmd.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "philadelphia_pennsylvania = db[collection]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### File Sizes : I want to showcase that my file has successfully converted from OSM to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Below I printed out the file size to compare JSON and the original file. The compressed file size that I used for submission was 45.6 MB. The uncompressed files are listed below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original OSM file is 658.378436 MB\n",
      "The JSON file is 741.287115 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print 'The original OSM file is {} MB'.format(os.path.getsize(OSM_FILE)/1.0e6) #formats OSM file from bytes to megabytes\n",
    "print 'The JSON file is {} MB'.format(os.path.getsize(OSM_FILE + \".json\")/1.0e6)#formats JSON file from bytes to megabytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Number of Unique Users : Showcasing how many users tells us how many individuals contributed to the Philadelphia open street map dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 1952\n"
     ]
    }
   ],
   "source": [
    "number_of_unique_users = len(philadelphia_pennsylvania.distinct('created.user'))\n",
    "print 'Number of unique users: {}'.format(number_of_unique_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### The JSON file has 10 less users in comparison to the orginal OSM XML file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Number of Nodes and Ways "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 2959699\n",
      "Number of ways: 290523\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Parse through JSON file to count number of nodes and ways tags\"\"\"\n",
    "print \"Number of nodes:\",philadelphia_pennsylvania.find({'type':'node'}).count()\n",
    "print \"Number of ways:\",philadelphia_pennsylvania.find({'type':'way'}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Number of Unique Users  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1952"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(philadelphia_pennsylvania.distinct('created.user'))#using len to give count, and dot notation to find how many unique user in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Name of top 5 contributers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'count': 797931, u'_id': u'dchiles'}, {u'count': 561902, u'_id': u'woodpeck_fixbot'}, {u'count': 295993, u'_id': u'NJDataUploads'}, {u'count': 106141, u'_id': u'kylegiusti'}, {u'count': 104633, u'_id': u'WesWeaver'}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Find top contributers to the Philadelphia data set\"\"\"\n",
    "result = philadelphia_pennsylvania.aggregate( [\n",
    "                                         { \"$group\" : {\"_id\" : \"$created.user\", #using dot notation to group id's, with using \"created.user\" to..\n",
    "                                        \"count\" : { \"$sum\" : 1} } },# count how many users \n",
    "                                        { \"$sort\" : {\"count\" : -1} }, # sort the count in desc from greatest to least to give us top 5\n",
    "                                        { \"$limit\" : 5 } ] ) # limit 5 in the ouputs \n",
    "\n",
    "print(list(result))# prints top 5 contriubters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further data exploration *****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Top 10 amenities in Philadelphia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'count': 5331, u'_id': u'parking'}, {u'count': 2143, u'_id': u'school'}, {u'count': 1281, u'_id': u'restaurant'}, {u'count': 1125, u'_id': u'place_of_worship'}, {u'count': 523, u'_id': u'fast_food'}, {u'count': 516, u'_id': u'fire_station'}, {u'count': 390, u'_id': u'bank'}, {u'count': 350, u'_id': u'fuel'}, {u'count': 328, u'_id': u'social_facility'}, {u'count': 273, u'_id': u'cafe'}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"The following aggregation pipeline showcases the top 10 amenities in Philadelphia\"\"\"\n",
    "amenity = philadelphia_pennsylvania.aggregate([{'$match': {'amenity': {'$exists': 1}}}, # finding amenities in the data\n",
    "                                {'$group': {'_id': '$amenity', \n",
    "                                            'count': {'$sum': 1}}}, ## grouping and adding amenities \n",
    "                                {'$sort': {'count': -1}}, ## sorting in descending order \n",
    "                                {'$limit': 10}])## limits output to top 10 amenities\n",
    "print(list(amenity))# print list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Top 5 cuisine options "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'Food': None, u'Count': 594}, {u'Food': u'pizza', u'Count': 138}, {u'Food': u'italian', u'Count': 68}, {u'Food': u'chinese', u'Count': 66}, {u'Food': u'american', u'Count': 60}]\n"
     ]
    }
   ],
   "source": [
    "cuisine = philadelphia_pennsylvania.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1},#finds amenities \n",
    "                                 \"amenity\":\"restaurant\",}},      \n",
    "                      {\"$group\":{\"_id\":{\"Food\":\"$cuisine\"},# groups my cuisine values in the dataset \n",
    "                                 \"count\":{\"$sum\":1}}}, # counts cuisine values \n",
    "                      {\"$project\":{\"_id\":0,\n",
    "                                  \"Food\":\"$_id.Food\",\n",
    "                                  \"Count\":\"$count\"}},\n",
    "                      {\"$sort\":{\"Count\":-1}}, \n",
    "                      {\"$limit\":5}])\n",
    "\n",
    "\n",
    "print(list(cuisine)) # prints output to notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### The output showcases that the first count with the most restaurants aren't even CATEGORIZED as a group. So there is potential here to improve the OSM site and to only allow inputs of restaurants with a category of what type of food is served"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Below I have created an aggregation that finds all places containing the word 'cheesesteak', a famous sandwich that Philadelpia is know for. So just for fun I wanted to see how many places in the data set contained that keyword. Also for fun and for even further analysis I think it would be cool to see if these sandwiches are a college students favorite and if the Philly cheesesteak shops located near campuses are more profitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'Count': 1281}]\n"
     ]
    }
   ],
   "source": [
    "cheesesteak = philadelphia_pennsylvania.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1},#finds amenities \n",
    "                                 \"amenity\":\"restaurant\",}},      \n",
    "                      {\"$group\":{\"_id\":{\"Food\":\"$cheesesteak\"},# groups my philly values in the dataset \n",
    "                                 \"count\":{\"$sum\":1}}}, # counts philly values \n",
    "                      {\"$project\":{\"_id\":0,\n",
    "                                  \"Count\":\"$count\"}},\n",
    "                      {\"$sort\":{\"Count\":-1}}])\n",
    "print(list(cheesesteak))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Here I found all the cafe's in Philadelphia : I'm looking into how many cafes are in Philly to fill my interest to see if Philadelphia is a coffee drinking kind of city. I would like to take these findings to discuss in my concluding statement to determine if theres a way to add implementation to the OSM site to find a correlation between coffee shops and colleges. Much like what I though of earlier in my evaluation about Philly cheesesteaks being a hit amoungst college kids, and if being in a certain location in relation to colleges led to more profitability for the overall business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'count': 45, u'_id': u'Starbucks'}, {u'count': 35, u'_id': u\"Dunkin' Donuts\"}, {u'count': 9, u'_id': None}, {u'count': 7, u'_id': u'Dunkin Donuts'}, {u'count': 4, u'_id': u'Green Line Cafe'}, {u'count': 3, u'_id': u'Starbucks Coffee'}, {u'count': 3, u'_id': u'OCF Coffee House'}, {u'count': 3, u'_id': u\"Saxby's Coffee\"}, {u'count': 2, u'_id': u'Cosi'}, {u'count': 2, u'_id': u'High Point Cafe'}]\n"
     ]
    }
   ],
   "source": [
    "cafe = philadelphia_pennsylvania.aggregate([ #start agregation pipeling to find cafes \n",
    "                {\"$match\": {\"amenity\": \"cafe\" }}, # find cafes in the data set \n",
    "                 {\"$group\": {\"_id\": '$name', \"count\": {\"$sum\": 1}}}, # group aggregation by cafe name and add to pipeline \n",
    "                 {\"$sort\": {\"count\": -1}}, # since indexing starts at 0. subract 1 to get output of 10 \n",
    "                 {\"$limit\": 10} # gives output of 10 cafes \n",
    "])\n",
    "print(list(cafe)) # prints output to notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here I found all of the colleges in Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'count': 2, u'_id': u'Wilson Hall East'}, {u'count': 1, u'_id': u'Maintenance (MW)'}, {u'count': 1, u'_id': u'William K. McDaniel Integrated Learning Resource Center #401'}, {u'count': 1, u'_id': u'Liberal Arts (LA)'}, {u'count': 1, u'_id': u'Science and Allied Health (MS)'}, {u'count': 1, u'_id': u'Roosevelt Hall'}, {u'count': 1, u'_id': u'Laurel Hall'}, {u'count': 1, u'_id': u'Community College of Philadelphia - West Regional Center'}, {u'count': 1, u'_id': u'Peirce College'}, {u'count': 1, u'_id': u'Technology & Engineering Center (TEC)'}]\n"
     ]
    }
   ],
   "source": [
    "college = philadelphia_pennsylvania.aggregate([\n",
    "                {\"$match\": {\"amenity\": \"college\" }},#find colleges \n",
    "                 {\"$group\": {\"_id\": '$name', \"count\": {\"$sum\": 1}}},# count colleges and add to list \n",
    "                 {\"$sort\": {\"count\": -1}}, # since indexing starts at 0. subtract 1 to get 10 \n",
    "                 {\"$limit\": 10}#gives me top 10 colleges \n",
    "])\n",
    "print(list(college)) # prints output to notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### While auditing the data I updated zipcodes and addresses to a uniform format so that the data showed consistancy. I noticed while running my MongoDB aggregations that for cuisine types, the first \"count\" print out didn't have a category for what type of food was featured at the restaurant. So there is room for improvement with importing content into the OSM site. I would prefer if content could only be added to the site if it meets certain requirements such as having a proper cuisine description. That way when someone let's says uses an app and wants to find restaurants with a certain keyword, they can find all restaurants nearby that features that certain cuisine that they are looking for. I wouldn't see any problem implementing this feature into OSM, I feel this would be an easy fix for the data set. Also, while performing aggregations on the file using MongoDB I looked into how many colleges and cafes were in the file. With this information I would like to see if cafes located near colleges were more profitable than ones that weren't near a college. And maybe report that data to a site that may be looking for best places to build proiftable coffee shops. I definetly think there will be a correlation between cafes and universities in the data set. In order to implement the feature to find coffee and college locations you would need to use geospatial indexing. This feature would be implemented in MongoDB, and was covered in the lesson videos. Some problems you may run into would be, lets say, trying to find colleges, and Universities in the area and not find all the schools. For instance, kids in middle school in my opinion should not be drinking highly caffeinated beverages such as coffee at such a young age. So you would want to make sure the data that you are looking at is cleaned and would give the correct correlation output between coffee shops and colleges or universities( and entirely disclude k-12 schools) to present to individuals who want to open coffee shops in the area."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
